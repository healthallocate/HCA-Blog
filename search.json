[
  {
    "objectID": "posts/uscrs_intervals.html",
    "href": "posts/uscrs_intervals.html",
    "title": "Constructing Intervals for the US-CRS",
    "section": "",
    "text": "This article serves as an explanation for the process of creating the 14-day interval data used in “Development and Validation of a Risk Score Predicting Death Without Transplant in Adult Heart Transplant Candidates” by Zhang, Narang, Jasseron, et al., JAMA, Feb 2024.\nNote: Any data used in this post are fabricated and are unrelated to the actual data used in constructing the US-CRS model.\n\n1. Setup of the data\nOne of the more difficult aspects of a statistical project, in my opinion, involves the tidying and setup of your initial data. Outside of coursework, rarely will you see data that is ready to go for analysis. It will often be partially missing, contain errors (especially if a human is involved in entering it, which will likely be the case!), or require some preparation in order to answer a question. We focus on this last aspect here.\nThe US-CRS model begins with data on patients who are on the wait list for a heart transplant that is available from the Scientific Registry of Transplant Recipients (SRTR). Each patient will have clinical data- think things like blood pressure or lab tests- recorded when they get on the wait list, and recorded again if something occurs, such as being transplanted.\nThis type of data is often referred to as panel data or longitudinal data. Each candidate also has a time component: how long on the wait list. A person might be on the wait list for 112 days, but have 5 events during these 112 days, each with a new set of clinical data. Start time is when time is 0.\n\n\n\n\n\nID_Number\nTime\nBlood_Pressure\n\n\n\n\n1\n0\n121\n\n\n1\n14\n134\n\n\n1\n42\n123\n\n\n1\n98\n127\n\n\n1\n112\n129\n\n\n\n\n\n\n\nInstead of these uneven chunks of time, we can break the data down into even, 14-day chunks:\n\n\n\n\n\nID_Number\nTime\nBlood_Pressure\n\n\n\n\n1\n0\n121\n\n\n1\n14\n134\n\n\n1\n28\n134\n\n\n1\n42\n123\n\n\n1\n56\n123\n\n\n1\n70\n123\n\n\n1\n84\n123\n\n\n1\n98\n127\n\n\n1\n112\n129\n\n\n\n\n\n\n\nThis process is known as discretization, as we are breaking the flow of time on the wait list into even individual, or discrete, blocks. We picked 14 days for each block, since that was the most common amount of time for a patient to spend at a priority level before priority could be reconsidered, according to official Organ Procurement and Transplantation Network (OPTN) guidelines.\nWe do this so that we can use the most up-to-date clinical data when creating a measure of medical urgency for transplantation. For a situation like the one below, the discrete blocks capture the many changes in blood pressure:\n\n\n\n\n\n\n\n\n\n\n\n2. The possible problems\nThe example below has all the chunks divisible by 14, making discretization easier. In reality, data is a lot more messy, and there are some problematic cases to consider:\n1. The ending time isn’t divisible by 14.\nInstead of 112 days, which is divisible by 14, the wait list total time is 113 days. We include the last block, which goes up to 126 days, despite the individual only spending 1 more day on the list. We do this because that’s when they got their most recent clinical data. On day 112, there’s no way to know what the results of those clinical measurements would be tomorrow.\n2. There are gaps between data, which create empty blocks.\nThe most recent data is used to fill in the gap. If a patient had a blood pressure of 120 at 14 days, and 130 at 42 days, the block for 28 has 120 for blood pressure. This idea is known as carrying forward data, and is used in other official allocation scores, such as the Model for End-Stage Liver Disease (MELD).\nWhat if the very first data point doesn’t exist, so that we don’t observe a value for blood pressure until 42 days? In that case, we use missing data approaches, which replace the gap with a statistical median (middle) value or “normal” values for heart transplant patients obtained from the clinical literature.\n3. In a single 14-day block, the data gets updated.\nSuppose the data gets updated at 8 days, in the middle of a block. In that case, the update will be transferred to the next block (14 days), to prevent the loss of the original data at 7 days, while also incorporating the newer data. This is how the original data would look:\n\n\n\n\n\nID_Number\nTime\nBlood_Pressure\n\n\n\n\n1\n0\n122\n\n\n1\n8\n132\n\n\n1\n50\n124\n\n\n\n\n\n\n\nAnd once discretized, it would look like this:\n\n\n\n\n\nID_Number\nTime\nBlood_Pressure\n\n\n\n\n1\n0\n122\n\n\n1\n14\n132\n\n\n1\n28\n132\n\n\n1\n42\n124\n\n\n\n\n\n\n\n\n\n3. Bringing it all together\nReturning to the previous example, let’s modify it so that there is now a missing gap in the data:\n\n\n\n\n\nID_Number\nTime\nBlood_Pressure\n\n\n\n\n1\n0\n122\n\n\n1\n8\n132\n\n\n1\n50\n\n\n\n1\n60\n124\n\n\n\n\n\n\n\nWe want to discretize this example dataset, which has every problem we previously described. We first create the dataset df_setup, and create a counts variable, which represents the number of 14-day blocks. The ceiling function ensures that we do not round down and lose time. For the first row, with 0 days, that still counts as a block, so we change any counts with 0 to 1.\nNote: ID number is added here and acts as a sanity check for when you have multiple patients.\n\ndf &lt;- data.frame(\n  'ID_Number' = c(1, 1, 1, 1),\n  'Time' = c(0, 8, 50, 60),\n  'Blood_Pressure' = c(122, 132, NA_integer_, 124))\n\n\ndf_setup &lt;- data.frame('ID_Number' = df$ID_Number,\n                       'Counts' = ceiling(df$Time / 14))\ndf_setup$Counts[df_setup$Counts == 0] &lt;- 1\n\nkable(df_setup, align='c') %&gt;%\n  kable_styling(position='center', full_width = F)\n\n\n\n\nID_Number\nCounts\n\n\n\n\n1\n1\n\n\n1\n1\n\n\n1\n4\n\n\n1\n5\n\n\n\n\n\n\n\nThe goal of the counts variable is to tell us how many times we need to repeat each row of the original data. In other words, we create a new row_reps that gives us a vector of the row number repeated the correct number of times, and can apply it to the original data to form our blocked result, df_blocked (note that the row numbers, 3, 3.1, 3.2, 3.3 show that row 3 have been correctly repeated 3 times):\n\nrow_reps &lt;- rep(1:nrow(df), df_setup$Counts)\ndf_blocked &lt;- df[row_reps, ]\n\nkable(df_blocked, align='c', row.names = T) %&gt;%\n  kable_styling(position='center', full_width = F)\n\n\n\n\n\nID_Number\nTime\nBlood_Pressure\n\n\n\n\n1\n1\n0\n122\n\n\n2\n1\n8\n132\n\n\n3\n1\n50\n\n\n\n3.1\n1\n50\n\n\n\n3.2\n1\n50\n\n\n\n3.3\n1\n50\n\n\n\n4\n1\n60\n124\n\n\n4.1\n1\n60\n124\n\n\n4.2\n1\n60\n124\n\n\n4.3\n1\n60\n124\n\n\n4.4\n1\n60\n124\n\n\n\n\n\n\n\nAfter correcting time, we still need to account for the problematic cases described earlier:\n\ndf_blocked &lt;- df_blocked %&gt;% \n  mutate(\n    Block = row_number(),\n    Time = 14 * (Block - 1)) %&gt;%\n  relocate(Block, .before = Time)\n\nkable(df_blocked, align='c', row.names = F) %&gt;%\n  kable_styling(position='center', full_width = F)\n\n\n\n\nID_Number\nBlock\nTime\nBlood_Pressure\n\n\n\n\n1\n1\n0\n122\n\n\n1\n2\n14\n132\n\n\n1\n3\n28\n\n\n\n1\n4\n42\n\n\n\n1\n5\n56\n\n\n\n1\n6\n70\n\n\n\n1\n7\n84\n124\n\n\n1\n8\n98\n124\n\n\n1\n9\n112\n124\n\n\n1\n10\n126\n124\n\n\n1\n11\n140\n124\n\n\n\n\n\n\n\nFirst, the extra blocks are removed. Then, we check on the initial values, final values, and previous values against the original data, row-by-row.\n\nmax_time &lt;- ceiling(max(df$Time) / 14) * 14 \n\ndf_blocked &lt;- df_blocked %&gt;%\n  group_by(ID_Number) %&gt;%\n  filter(Time &lt;= max_time | max_time == 0)\n\nfor (i in 1:(nrow(df_blocked))) {\n  \n  ID_at_index &lt;- df_blocked[i, ]$ID_Number\n  \n  \n  if (df_blocked$Time[i] == 0) {\n    initial_values &lt;- df %&gt;% \n      filter(ID_Number == ID_at_index & Time == 0) %&gt;%\n      select(Blood_Pressure)\n    \n    df_blocked$Blood_Pressure[i] &lt;- initial_values %&gt;% pull(Blood_Pressure)\n  } \n  \n  \n  else if (df_blocked$Time[i] == max(df$Time)) {\n      final_values &lt;- df %&gt;% \n      filter(ID_Number == ID_at_index & Time == max(Time)) %&gt;%\n      select(Blood_Pressure)\n      \n      df_blocked$Blood_Pressure[i] &lt;- final_values %&gt;% pull(Blood_Pressure)\n  } \n  \n  \n  else {\n    previous_values &lt;- df %&gt;%\n      filter(ID_Number == ID_at_index &\n              Time &lt;= df_blocked$Time[i]) %&gt;%\n      filter(Time == max(Time)) %&gt;%\n      select(Blood_Pressure)\n    \n    df_blocked$Blood_Pressure[i] &lt;- previous_values %&gt;% pull(Blood_Pressure)\n  }\n}\n\n\nkable(df_blocked, align='c', row.names = F) %&gt;%\n  kable_styling(position='center', full_width = F)\n\n\n\n\nID_Number\nBlock\nTime\nBlood_Pressure\n\n\n\n\n1\n1\n0\n122\n\n\n1\n2\n14\n132\n\n\n1\n3\n28\n132\n\n\n1\n4\n42\n132\n\n\n1\n5\n56\n\n\n\n1\n6\n70\n124\n\n\n\n\n\n\n\nWhat remains is the single missing value, which can be easily fixed by carrying forward the previous value:\n\ndf_blocked &lt;- df_blocked %&gt;%\n  group_by(ID_Number) %&gt;%\n  fill(Blood_Pressure, .direction = 'down')\n\n\nkable(df_blocked, align='c', row.names = F) %&gt;%\n  kable_styling(position='center', full_width = F)\n\n\n\n\nID_Number\nBlock\nTime\nBlood_Pressure\n\n\n\n\n1\n1\n0\n122\n\n\n1\n2\n14\n132\n\n\n1\n3\n28\n132\n\n\n1\n4\n42\n132\n\n\n1\n5\n56\n132\n\n\n1\n6\n70\n124"
  },
  {
    "objectID": "posts/prop_score.html",
    "href": "posts/prop_score.html",
    "title": "Propensity Score Matching",
    "section": "",
    "text": "The purpose of propensity score matching is to identify observations where the covariates that determine assignment to a particular group have similar values across different groups. In our example, we want to identify recipients of single kidney transplants whose Expected Post Transplant Survival (EPTS) characteristics are similar to those of recipients of en bloc kidneys. By identifying such patients, we will be able to better compare post-transplant survival outcomes by accounting for other possible confounding factors. In this case, these covariates are age, dialysis, diabetes, and previous transplant.\nNote that we did not match based on donor characteristics. This is because after donor kidneys are assigned a sequence, they are treated equally to other kidneys in that sequence, so donor characteristics have no additional influence on assignment to each patient. When propensity score matching it is important to match only on those covariates which impact assignment of the treatment to each group.\nHere’s a look at our dataframe:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nenbloc_under8\nREC_AGE_AT_TX\ndialysis_duration\nno_dial\nrec_diabetes\nCAN_PREV_TX\n\n\n\n\n1\n0\n46\n1.7397260\n0\n0\n0\n\n\n34\n0\n64\n0.0000000\n1\n1\n0\n\n\n47\n0\n25\n0.0000000\n1\n0\n1\n\n\n74\n0\n51\n0.0000000\n1\n1\n0\n\n\n81\n0\n66\n2.7315068\n0\n1\n0\n\n\n103\n0\n43\n1.8246575\n0\n0\n0\n\n\n106\n0\n67\n0.4958904\n0\n1\n0\n\n\n108\n0\n51\n0.0000000\n1\n0\n0\n\n\n109\n0\n43\n0.6136986\n0\n0\n0\n\n\n111\n0\n57\n0.9260274\n0\n0\n0\n\n\n\n\n\n\nenbloc_under8 is an indicator for whether the patient received an en bloc kidney from a donor weighing &lt; 8kg\nREC_AGE_AT_TX is the recipient’s age at time of transplant\ndialysis_duration is the time in years that a patient was on dialysis before transplant\nno_dial is an indicator for whether the patient never received dialysis\nrec_diabetes is an indicator for whether the patient had diabetes\nCAN_PREV_TX is an indicator for whether the patient had received a transplant previously.\n\nIn this example, we are going to do 1-to-1 matching, where for each recipient of an ebloc from a donor &lt; 8kg, we are finding 1 recipient of a sequence A SKT with similar characteristics. This is the most common form of propensity score matching but not the only (see Austin 2011)\nTo perform propensity score matching, we use the MatchIt library in R. To ensure that the covariates are sufficiently similar, we include cross terms that allow the standardized mean differences of the covariates to be &lt; 0.1.\n\nmatch_obj = matchit(enbloc_under8 ~ REC_AGE_AT_TX + dialysis_duration + no_dial + rec_diabetes + CAN_PREV_TX + REC_AGE_AT_TX*no_dial + REC_AGE_AT_TX*rec_diabetes, data = seq_a_data_under, method = \"nearest\", distance =\"glm\",\n  ratio = 1,\n  replace = FALSE)\n\nModel specifications:\n\nmethod = “nearest” specifies nearest neighbor matching\ndistance = “glm” specifies the estimation of propensity scores using logistic regression\nratio = 1 specifies 1:1 matching\nreplace = “FALSE” specifies a unique SKT match for each en bloc recipient\n\nTo return a dataset from this matching process, use the match.data() function as follows:\n\nmatch_data_under = match.data(match_obj)\n\nTo visualize the standardized mean differences in the covariates, use the love.plot() function from the cobalt library\n\nlove.plot(match_obj, stats = \"m\", binary = \"std\", threshold = .1, \n          var.order = \"unadjusted\", var.names = v)\n\n\n\n\n\n\n\n\n\nstats = “m” specifies the calculation of mean differences\nbinary = “std” specifies the standardized mean difference\nthreshold = 0.1 includes boundary lines at -0.1 and 0.1 to display the threshold\nvar.order = “unadjusted” displays the variables in order from smallest to largest unadjusted standardized mean difference\nvar.names = v displays the vector v that describes the variable names\n\nAs we can see in the love plot, without matching, recipients of en blocs from donors &lt; 8kg have significantly different values of EPTS characteristics than recipients of sequence A SKTs. By matching on these characteristics, we are able to identify patients who have similar values for these characteristics, leading to standardized mean differences that are all below 0.1.\nReferences:\nAustin PC. An Introduction to Propensity Score Methods for Reducing the Effects of Confounding in Observational Studies. Multivariate Behav Res. 2011;46(3):399-424. doi:10.1080/00273171.2011.568786"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "HCA Blog",
    "section": "",
    "text": "Welcome to the Healthcare Allocation Lab Blog!\nHere you will find instructional posts on best statistical practices when working with data from the Scientific Registry of Transplant Recipients (SRTR).\nFor source code from our projects, please visit https://github.com/healthallocate\n\n\nPosts\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime Varying EPTS\n\n\n\nData Structures\n\n\nKidney Allocation\n\n\nR\n\n\n\n\n\n\n\nMolly H. White\n\n\nFeb 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nConstructing Intervals for the US-CRS\n\n\n\nData Structures\n\n\nHeart Allocation\n\n\nR\n\n\n\n\n\n\n\nKevin C. Zhang\n\n\nFeb 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPropensity Score Matching\n\n\n\nAnalysis\n\n\nKidney Allocation\n\n\nR\n\n\n\n\n\n\n\nMolly H. White\n\n\nFeb 7, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/time_varying_epts.html",
    "href": "posts/time_varying_epts.html",
    "title": "Time Varying EPTS",
    "section": "",
    "text": "In the SRTR Standard Analysis Files, the CAND_KIPA file includes information on candidates listed for kidney and/or pancreas transplants. From this file, it is possible to calculate a candidate EPTS score at listing, but it does not directly account for the change in dialysis time and age during a patient’s time on the waitlist that can lead to higher EPTS scores over time. To perform analyses on EPTS scores that change over time, it is possible to request an enhanced SAF from the SRTR that includes time-varying EPTS. Alternatively, you can consctruct a discrete time dataset that can be used to calculate EPTS at different periods during a candidate’s time on the waitlist. In this post we will address how we constructed such a dataset for our manuscript Association of Race and Ethnicity with Priority for Deceased Donor Kidney Transplant.\nFor this post, we use fabricated data to demonstrate the process of constructing such a dataset. Let’s take a look at our data:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPX_ID\nmin_list_date\nprevious_TX\ndialysis\nwaitlist_end_date\ndiabetes\nage_months\nCAN_DIAL_DT\ndialysis_time_at_list\nwait_time\n\n\n\n\n1\n2015-09-03\n0\n0\n2016-02-09\n0\n602\n2015-11-15\n0.0000000\n159 days\n\n\n2\n2012-02-03\n0\n1\n2012-04-16\n0\n439\n2011-09-20\n0.2000000\n73 days\n\n\n3\n2014-04-30\n1\n0\n2014-12-20\n0\n339\nNA\n0.0000000\n234 days\n\n\n4\n2012-05-12\n0\n1\n2012-06-29\n0\n629\n2012-01-02\n0.1315068\n48 days\n\n\n5\n2011-02-21\n1\n0\n2011-09-04\n1\n546\nNA\n0.0000000\n195 days\n\n\n6\n2012-12-11\n0\n1\n2013-04-22\n0\n528\n2011-11-12\n0.3616438\n132 days\n\n\n\n\n\n\nPX_ID is a unique patient identifier\nmin_list_date is the earliest date a patient is listed for a transplant. This takes into account patients who are listed at multiple centers concurrently. We will explain how to address such patients in another post.\nprevious_TX is an indicator for whether the patient has received a previous transplant\ndialysis is an indicator for whether the patient was on dialysis when they were listed\nwaitlist_end_date is the date that the patient received a transplant or was otherwise removed from the waiting list\nwait_time is the time between the candidate’s listing and their waitlist end date\ndialysis_time_at_list is how long the patient was on dialysis before being placed on the waitlist\ndiabetes is an indicator for whether the candidate has diabetes\nCAN_DIAL_DT is the date the candidate started dialysis (if at all)\nage_months is the candidate’s age in months at listing\n\nWith these variables we would be able to calculate a patient’s EPTS score at listing, but neither the age nor dialysis time variables capture changes over time. To address this, we can create a discrete time data set with 1 month intervals such that the age and dialysis time increase every month that the candidate is on the waitlist.\nFirst, we will flag patient’s who were pre-emptively listed and then started dialysis during their time on the waitlist:\n\ndf_epts_varying$dialysis_during_waitlist &lt;- ifelse(df_epts_varying$CAN_DIAL_DT &gt; df_epts_varying$min_list_date, 1, 0)\ndf_epts_varying$dialysis_during_waitlist[is.na(df_epts_varying$dialysis_during_waitlist)] &lt;- 0\n\nWe will then calculate the total months that each patient was on the waitlist:\n\ndf_epts_varying = df_epts_varying  %&gt;% mutate(time_period = as.integer(floor((wait_time)*12/365)))\n\nTo properly encode the dialysis time for patients who begin dialysis after listing, we use a time_until_dialysis variable, which we will compare to the patient’s time on the waitlist to trigger the dialysis_time variable to start increasing\n\ndf_epts_varying = df_epts_varying %&gt;% mutate(time_until_dialysis = ifelse(dialysis_during_waitlist == 1, as.integer(floor((CAN_DIAL_DT - min_list_date)*12/365)), 0))\n\nUsing the time period variable, we construct a dataset which has an observation for each month the patient is on the waitlist. This new dataset also uses the age in month at listing for the first observed age and then increases by 1 month for every new observation for that patient. Similarly, it increases dialysis time by 1 month for each observation for patients on dialysis.\n\nexpanded_data &lt;- df_epts_varying %&gt;%\n  tidyr::uncount(weights = time_period + 1) %&gt;%\n  group_by(PX_ID) %&gt;%\n  mutate(time = ifelse(row_number() &lt;= time_period + 1, row_number() - 1, NA),\n    time = ifelse(is.na(time), max(time, na.rm = TRUE), time),\n    age = age_months/12\n  ) %&gt;%\n  mutate(age = age + row_number()/12)\n\nexpanded_data = expanded_data %&gt;% \n  mutate(dialysis_after_waitlist = case_when(\n    dialysis_during_waitlist == 1 & (time - time_until_dialysis) &lt; 0 ~ 0, \n    dialysis_during_waitlist == 1 & (time - time_until_dialysis) &gt;= 0 ~ (time - time_until_dialysis), \n    dialysis_during_waitlist == 0 & dialysis == 1 ~ (time - time_until_dialysis),\n    TRUE ~ 0))\n\nexpanded_data = expanded_data %&gt;% mutate(dialysis_time = dialysis_time_at_list + dialysis_after_waitlist/12)\n\nTo calculate the EPTS score for each patient during each month on the waitlist, we prep the variables as follows:\n\ndf_months &lt;- expanded_data %&gt;%\n  select(PX_ID, age, dialysis, previous_TX, dialysis_time, diabetes, time) %&gt;%\n  mutate(age = as.numeric(age),\n         dialysis_time = as.numeric(dialysis_time),\n         diabetes = as.numeric(as.character(diabetes)),\n         dialysis = ifelse(dialysis_time &gt; 0, 1, 0))\n\nand then use the EPTS mapping table (from 2021):\n\ndf_months &lt;- df_months %&gt;% \n  mutate(raw_epts = \n           0.047*pmax(age - 25, 0) - \n           0.015*(diabetes==1)*pmax(age - 25, 0) +\n           0.398*(previous_TX==1) - 0.237*(diabetes==1)*(previous_TX==1) +\n           0.315*log(dialysis_time + 1) - 0.099*(diabetes==1)*log(dialysis_time + 1) +\n           0.130*(dialysis_time == 0) - 0.348*(diabetes==1)*(dialysis_time == 0) +  \n           1.262*(diabetes==1))\n\n\ndf_months &lt;- df_months %&gt;%\n  mutate(percentile_epts = case_when(\n           raw_epts &lt;= 0.01842385502984 ~ 0,\n           raw_epts &lt;= 0.23587063655031 ~ 1,\n           raw_epts &lt;= 0.41885215605749 ~ 2,\n           raw_epts &lt;= 0.52800000000000 ~ 3,\n           raw_epts &lt;= 0.62852561015766 ~ 4,\n           \n           raw_epts &lt;= 0.71352703627652 ~ 5,\n           raw_epts &lt;= 0.79220296573099 ~ 6,\n           raw_epts &lt;= 0.86714433496842 ~ 7,\n           raw_epts &lt;= 0.93047980835044 ~ 8,\n           raw_epts &lt;= 0.99391854893908 ~ 9,\n           \n           raw_epts &lt;= 1.05598976270380 ~ 10,\n           raw_epts &lt;= 1.11434794060852 ~ 11,\n           raw_epts &lt;= 1.17045574165807 ~ 12,\n           raw_epts &lt;= 1.22030049020253 ~ 13,\n           raw_epts &lt;= 1.27212500074301 ~ 14,\n           \n           raw_epts &lt;= 1.31913766912690 ~ 15,\n           raw_epts &lt;= 1.36438535249829 ~ 16,\n           raw_epts &lt;= 1.41168240930869 ~ 17,\n           raw_epts &lt;= 1.45433196440794 ~ 18,\n           raw_epts &lt;= 1.49473716632444 ~ 19,\n           \n           raw_epts &lt;= 1.53514236824093 ~ 20,\n           raw_epts &lt;= 1.57300507228037 ~ 21,\n           raw_epts &lt;= 1.60810335386721 ~ 22,\n           raw_epts &lt;= 1.64297604380561 ~ 23,\n           raw_epts &lt;= 1.67354110859117 ~ 24,\n           \n           raw_epts &lt;= 1.70255373032170 ~ 25,\n           raw_epts &lt;= 1.73150650239562 ~ 26,\n           raw_epts &lt;= 1.75869376757638 ~ 27,\n           raw_epts &lt;= 1.78477960301164 ~ 28,\n           raw_epts &lt;= 1.81180219028063 ~ 29,\n           \n           raw_epts &lt;= 1.83683495289066 ~ 30,\n           raw_epts &lt;= 1.86060232717317 ~ 31,\n           raw_epts &lt;= 1.88375164234518 ~ 32,\n           raw_epts &lt;= 1.90727234572108 ~ 33,\n           raw_epts &lt;= 1.92941067761807 ~ 34,\n           \n           raw_epts &lt;= 1.95149964313427 ~ 35,\n           raw_epts &lt;= 1.97370841889117 ~ 36,\n           raw_epts &lt;= 1.99414162335253 ~ 37,\n           raw_epts &lt;= 2.01486542476192 ~ 38,\n           raw_epts &lt;= 2.03323308735222 ~ 39,\n           \n           raw_epts &lt;= 2.05397604380561 ~ 40,\n           raw_epts &lt;= 2.07327619854998 ~ 41,\n           raw_epts &lt;= 2.09202182261888 ~ 42,\n           raw_epts &lt;= 2.11055715263518 ~ 43,\n           raw_epts &lt;= 2.12710952613370 ~ 44,\n           \n           raw_epts &lt;= 2.14469472963723 ~ 45,\n           raw_epts &lt;= 2.16206639288159 ~ 46,\n           raw_epts &lt;= 2.17895804742641 ~ 47,\n           raw_epts &lt;= 2.19533620671360 ~ 48,\n           raw_epts &lt;= 2.21202975619422 ~ 49,\n           \n           raw_epts &lt;= 2.22830663928816 ~ 50,\n           raw_epts &lt;= 2.24486516084873 ~ 51,\n           raw_epts &lt;= 2.25934770704997 ~ 52,\n           raw_epts &lt;= 2.27457912196537 ~ 53,\n           raw_epts &lt;= 2.29007370896616 ~ 54,\n           \n           raw_epts &lt;= 2.30555527524319 ~ 55,\n           raw_epts &lt;= 2.32162833675565 ~ 56,\n           raw_epts &lt;= 2.33676297950084 ~ 57,\n           raw_epts &lt;= 2.35264238040105 ~ 58,\n           raw_epts &lt;= 2.36804654346338 ~ 59,\n           \n           raw_epts &lt;= 2.38288012607080 ~ 60,\n           raw_epts &lt;= 2.39744314980323 ~ 61,\n           raw_epts &lt;= 2.41176454483231 ~ 62,\n           raw_epts &lt;= 2.42661080994812 ~ 63,\n           raw_epts &lt;= 2.44143904753026 ~ 64,\n           \n           raw_epts &lt;= 2.45616599664439 ~ 65,\n           raw_epts &lt;= 2.47046406570842 ~ 66,\n           raw_epts &lt;= 2.48541673804140 ~ 67,\n           raw_epts &lt;= 2.50082593655723 ~ 68,\n           raw_epts &lt;= 2.51575906913073 ~ 69,\n           \n           raw_epts &lt;= 2.53179041411307 ~ 70,\n           raw_epts &lt;= 2.54847145496397 ~ 71,\n           raw_epts &lt;= 2.56450211494358 ~ 72,\n           raw_epts &lt;= 2.58056343072585 ~ 73,\n           raw_epts &lt;= 2.59622536132146 ~ 74,\n           \n           raw_epts &lt;= 2.61220575225961 ~ 75,\n           raw_epts &lt;= 2.62980229727812 ~ 76,\n           raw_epts &lt;= 2.64633742797854 ~ 77,\n           raw_epts &lt;= 2.66270836678796 ~ 78,\n           raw_epts &lt;= 2.68071428443369 ~ 79,\n           \n           raw_epts &lt;= 2.69965721597721 ~ 80,\n           raw_epts &lt;= 2.71924640657084 ~ 81,\n           raw_epts &lt;= 2.73853621699103 ~ 82,\n           raw_epts &lt;= 2.75778147760295 ~ 83,\n           raw_epts &lt;= 2.77728756159785 ~ 84,\n           \n           raw_epts &lt;= 2.79719224080293 ~ 85,\n           raw_epts &lt;= 2.81884538728167 ~ 86,\n           raw_epts &lt;= 2.83956718767238 ~ 87,\n           raw_epts &lt;= 2.86117343797221 ~ 88,\n           raw_epts &lt;= 2.88458357309819 ~ 89,\n           \n           raw_epts &lt;= 2.90679669457193 ~ 90,\n           raw_epts &lt;= 2.93187604974332 ~ 91,\n           raw_epts &lt;= 2.95563732458239 ~ 92,\n           raw_epts &lt;= 2.98192663471240 ~ 93,\n           raw_epts &lt;= 3.01041956645050 ~ 94,\n           \n           raw_epts &lt;= 3.04211557588171 ~ 95,\n           raw_epts &lt;= 3.07653689699372 ~ 96,\n           raw_epts &lt;= 3.11838513945413 ~ 97,\n           raw_epts &lt;= 3.17159971150431 ~ 98,\n           raw_epts &lt;= 3.24849418211424 ~ 99,\n           TRUE ~ 100)) \n  \n## Extra line to remove missings\ndf_months$percentile_epts[is.na(df_months$raw_epts)] &lt;- NA\n\nAs you can see below, this process results in a dataset that captures changes in age and dialysis time, allowing for the calculation of EPTS scores over a patient’s time on the waitlist. For this pre-empitvely listed candidate, being put on dialysis initially raises their EPTS score since “no dialysis” has a positive coefficient in the model. But over time, as dialysis time and age increases, their EPTS continues to increase."
  }
]